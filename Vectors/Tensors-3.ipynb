{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}a_{1} \\sin{\\left (y_{2} \\right )} \\cos{\\left (y_{3} \\right )} + a_{2} y_{1} \\cos{\\left (y_{2} \\right )} \\cos{\\left (y_{3} \\right )} - a_{3} y_{1} \\sin{\\left (y_{2} \\right )} \\sin{\\left (y_{3} \\right )}\\\\a_{1} \\sin{\\left (y_{2} \\right )} \\sin{\\left (y_{3} \\right )} + a_{2} y_{1} \\sin{\\left (y_{3} \\right )} \\cos{\\left (y_{2} \\right )} + a_{3} y_{1} \\sin{\\left (y_{2} \\right )} \\cos{\\left (y_{3} \\right )}\\\\a_{1} \\cos{\\left (y_{2} \\right )} - a_{2} y_{1} \\sin{\\left (y_{2} \\right )}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "⎡a₁⋅sin(y₂)⋅cos(y₃) + a₂⋅y₁⋅cos(y₂)⋅cos(y₃) - a₃⋅y₁⋅sin(y₂)⋅sin(y₃)⎤\n",
       "⎢                                                                  ⎥\n",
       "⎢a₁⋅sin(y₂)⋅sin(y₃) + a₂⋅y₁⋅sin(y₃)⋅cos(y₂) + a₃⋅y₁⋅sin(y₂)⋅cos(y₃)⎥\n",
       "⎢                                                                  ⎥\n",
       "⎣                    a₁⋅cos(y₂) - a₂⋅y₁⋅sin(y₂)                    ⎦"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does the contravariant vector look like symbolically after the transform ?\n",
    "a_1,a_2,a_3 = symbols('a_1,a_2,a_3')\n",
    "v_sph = Matrix([a_1,a_2,a_3])\n",
    "v_rect = J_1 * v_sph\n",
    "v_rect\n",
    "# vector in the cartesian coordinates from the spherical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contravariant Tensor\n",
    "   \n",
    "---\n",
    "If $\\mathbf T = (T^i) $ is a vector field (vector function of a vector variable) in the *unbarred* system such that $T^i = T^i(\\mathbf x) = T^i(x^j)$  and it can also be represented in the *barred* system via a coordinate transformation, then  $\\mathbf T$ is a <b>contravariant tensor of rank 1 </b> if the components \n",
    "   \n",
    "$ (T^{ \\color{red}{1}}, T^{ \\color{red}{2}}, \\cdots, T^{ \\color{red}{n}}) $ in the unbarred system\n",
    "   \n",
    "$ (\\bar{T}^{ \\color{blue}{1}},\\bar{T}^{ \\color{blue}{2}},\\cdots, \\bar{T}^{ \\color{blue}{n}}) $ in the barred system\n",
    "   \n",
    "are related by a transformation \n",
    "\n",
    "$$\\large\\bar{T}^{ \\color{blue}{i}} = \\frac{ \\partial \\bar{x}^{ \\color{blue}{i}} }{ \\partial x^{ \\color{red}{j}}} T^{ \\color{red}{j}} $$ \n",
    "   \n",
    "> A contravariant vector has components that change if the coordinates change, but the vector itself does not change. Under an operation like scaling or rotation, the components of a contravariant vector will make a change that cancels the operation. Examples include velocity of a fluid, displacement, acceleration.\n",
    "   \n",
    "> For example, $$\\frac{\\partial y^i}{\\partial t} =\\frac{\\partial y^i}{\\partial x^r}\\frac{\\partial x^r}{\\partial t}$$  \n",
    "> the term $\\frac{\\partial y^i}{\\partial x^r}$ defines the contravariant nature of this term. \n",
    "   \n",
    "> Note: this takes the form of the differential defined above, divided by the $\\partial t$, or the change in the  differential of the $y$ coordinates with respect to the $x$ coordinates through time. \n",
    "   \n",
    "with full-on red and blue notation \n",
    "   \n",
    "$$\\large\\color{blue}{\\bar{T}^{ i}} = \\frac{ \\partial \\color{blue}{\\bar{x}^{ i}} }{ \\partial \\color{red}{x^{ j}}} \\color{red}{T^{ j} }    \\qquad\\qquad (1.2)$$ \n",
    "   \n",
    "without the red and blue notation\n",
    "\n",
    "$$\\large\\bar{T}^{ i} = \\frac{ \\partial \\bar{x}^{ i} }{ \\partial x^{ j}} T^{ j} $$ \n",
    "   \n",
    "#### So in a *contravariant* tensor the *barred system* that we are converting to appears upstairs in the transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariant Tensor\n",
    "---\n",
    "The vector field $\\mathbf T$ is a covariant tensor is the components in the barred and unbarred coordinate systems obey the following transformation law \n",
    "   \n",
    "$$\\large\\bar{T}_{ \\color{blue}{i}} = \\frac{  \\partial x^{ \\color{red}{j}}  }{\\partial \\bar{x}^{ \\color{blue}{i}} } T_{ \\color{red}{j}} $$ \n",
    "   \n",
    "> A covariant vector has components that change like the coordinates change, The gradient of a scalar function (i.e. the potential) is a covariant tensor, (i.e. $\\mathbf F$ ) , also called a covariant vector.\n",
    "   \n",
    "> For example: $$\\nabla \\mathbf F = \\frac{\\partial F}{\\partial y^i}= \\frac{\\partial F}{\\partial x^p} \\frac{\\partial x^p}{\\partial y^i}$$ the term   $ \\frac{\\partial x^p}{\\partial y^i}$ defines the covariant nature of this. I could equally have use the $y$'s as the unbarred coordinates in both cases, resulting in the opposite appearance. \n",
    "   \n",
    "> Note: this takes the form of the chain rule defined above for a scalar valued function of a vector variable.\n",
    "\n",
    "   \n",
    "with the full-on red and blue notation\n",
    "   \n",
    "$$\\large\\color{blue}{\\bar{T}_{ i }} = \\frac{  \\partial \\color{red}{x^{ j }}  }{\\partial \\color{blue}{\\bar{x}^{ i } }} \\color{red}{T_{ j}} \\qquad\\qquad (1.3)$$ \n",
    "   \n",
    "without the red and blue notation\n",
    "\n",
    "$$\\large\\bar{T}_{ i } = \\frac{  \\partial x^{ j }  }{\\partial \\bar{x}^{ i } } T_{ j} $$ \n",
    "   \n",
    "#### So in a *covariant* tensor the coordinate system we are converting to appears *downstairs* in the transform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on the Jacobian Matrix\n",
    "> The contravariant tensor transforms with the Jacobian matrix of the system $\\bar{x}^k =\\bar{x}^k (x^j) $ \n",
    "\n",
    ">   \n",
    "> $$ \\bar {T}^i = [\\mathbf J]_j^i T^j $$ \n",
    ">    \n",
    "> where $$[\\mathbf J]_j^i = \\frac{\\partial \\bar{x}^i}{\\partial x^j} $$ \n",
    ">\n",
    "> so, we use the sum over the $j^{\\text{th}}$ column of $[\\mathbf J]$ multiplied by the $j^{\\text{th}}$ component of $T^j$ ... ie\n",
    "   \n",
    "> $\\bar {T}^1 = [\\mathbf J]_j^1 T^j =  \\frac{\\partial \\bar{x}^1}{\\partial x^1}T^1 +\\frac{\\partial \\bar{x}^1}{\\partial x^2}T^2 + \\frac{\\partial \\bar{x}^1}{\\partial x^3}T^3 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> The covariant tensor transforms with the Jacobian matrix of the system $x^j =x^j(\\bar{x}^k ) $ or the reciprocal of the\n",
    "> jacobian matrix of the system $\\bar{x}^k =\\bar{x}^k (x^j) $ \n",
    ">   \n",
    "> $$ \\bar {T}_i = [\\bar{\\mathbf J}] T_j  $$ \n",
    ">    \n",
    "> $\\bar {T}_1 =  \\frac{\\partial x^1}{\\partial \\bar{x}^1}T^1 +\\frac{\\partial x^2}{\\partial \\bar{x}^1}T^2 + \\frac{\\partial x^3}{\\partial \\bar{x}^1}T^3 $\n",
    "\n",
    "Note: Compute the inverse of the Jacobian matrix and compare to the reciprocal jacobian matix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}a_{1} \\sin{\\left (y_{2} \\right )} \\cos{\\left (y_{3} \\right )} + a_{2} y_{1} \\cos{\\left (y_{2} \\right )} \\cos{\\left (y_{3} \\right )} - a_{3} y_{1} \\sin{\\left (y_{2} \\right )} \\sin{\\left (y_{3} \\right )}\\\\a_{1} \\sin{\\left (y_{2} \\right )} \\sin{\\left (y_{3} \\right )} + a_{2} y_{1} \\sin{\\left (y_{3} \\right )} \\cos{\\left (y_{2} \\right )} + a_{3} y_{1} \\sin{\\left (y_{2} \\right )} \\cos{\\left (y_{3} \\right )}\\\\a_{1} \\cos{\\left (y_{2} \\right )} - a_{2} y_{1} \\sin{\\left (y_{2} \\right )}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "⎡a₁⋅sin(y₂)⋅cos(y₃) + a₂⋅y₁⋅cos(y₂)⋅cos(y₃) - a₃⋅y₁⋅sin(y₂)⋅sin(y₃)⎤\n",
       "⎢                                                                  ⎥\n",
       "⎢a₁⋅sin(y₂)⋅sin(y₃) + a₂⋅y₁⋅sin(y₃)⋅cos(y₂) + a₃⋅y₁⋅sin(y₂)⋅cos(y₃)⎥\n",
       "⎢                                                                  ⎥\n",
       "⎣                    a₁⋅cos(y₂) - a₂⋅y₁⋅sin(y₂)                    ⎦"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y__1 = Function('y__1')(t)\n",
    "y__2 = Function('y__2')(t)\n",
    "y__3 = Function('y__3')(t)\n",
    "\n",
    "# if we take our definition of a contravariant vector transformed from spherical to \n",
    "# rectangular coordinates, then set a_i = diff(y__i,t), the derivative ofthe coordinate\n",
    "# we find the result is the same as 3.61-3.63\n",
    "v_rect.subs({a_1:diff(y__1,t),a_2:diff(y__2,t),a_3:diff(y__3,t), y_1:y__1,y_2:y__2,y_3:y__3})\n",
    "v_rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with the above derivation with $\\dot{\\mathbf{y}} = \\left( \\dot{y}^1,\\dot{y}^2,\\dot{y}^3\\right) = \\left(a_1, a_2, a_3\\right)$ ... $\\sin(y^2) = s_2,\\ \\cos(y^2) = c_2 $ etc from above ( and of course ignoring the notation inconsistency with the subscript and superscript notation - this time - it becomes important later).\n",
    "\n",
    "   \n",
    "$$ \\dot{x}^1 = \\dot{y}^1 s_2 c_3 +y^1 \\dot{y}^2 c_2 c_3 - y^1 \\dot{y}^3 s_2  s_3 $$\n",
    "\n",
    "and\n",
    "   \n",
    "$$\\dot{x}^2 = \\dot{y}^1 s_2 s_3+y^1 c_2 \\dot{y}^2 s_3 + y^1 s_2 c_3\\dot{y}^3 $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\dot{x}^3 = \\dot{y}^1 c_2- s_2 y^1 \\dot{y}^2 $$\n",
    "   \n",
    "The terms in the tensor above are exactly the same as equations (3.61), (3.62) and (3.63) after the substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So I am confident that the tensor is correct, I am just not sure how to plot it.\n",
    "   \n",
    "> To plot this space curve given the velocity in spherical coordinates and arbitrary starting point, I will need the\n",
    "*absolute derivative*, defined later, because the curve contains acceleration as the velocity direction is always changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invariants\n",
    "Any quantity that does not change with a change of basis is called an invariant. For example, a scalar function of a vector variable, a potential $\\phi(x^i)$ is transformed to the barred coordinate system and still has the same value, therefore $\\phi$ is said to be <b>invariant</b> or a <b>tensor of rank zero</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Order Tensors\n",
    "---\n",
    "If there are $n^2$ quantities defining a matrix field, or matrix of scalar fields $\\mathbf T = T^{ij}(\\mathbf x) $ with components in both the barred and unbarred coordinate systems\n",
    "    \n",
    "#### Contravariant\n",
    "      \n",
    "$$\\large\\bar{T}^{ i r} = \\frac{ \\partial \\bar{x}^{ i} }{ \\partial \\smash{x^{ j}}} \\frac{ \\partial \\bar{x}^{ r} }{ \\partial x^{ s}} T^{ j s} \\qquad\\qquad (1.3)$$ \n",
    "\n",
    "#### Covariant\n",
    "   \n",
    "$$\\large\\bar{T}_{ i r } = \\frac{  \\partial x^{ j }  }{\\partial \\smash{\\bar{x}^{ i } }} \\frac{  \\partial x^{ s }  }{\\partial \\bar{x}^{ r } }T_{ j s} \\qquad\\qquad (1.4)$$ \n",
    "\n",
    "#### Mixed\n",
    "   \n",
    "$$\\large\\bar{T}^i_r = \\frac{ \\partial \\bar{x}^{ i} }{ \\partial \\smash{x^{ j}}} \\frac{  \\partial x^{ s }  }{\\partial \\bar{x}^{ r } }T^j_s \\qquad\\qquad (1.5)$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> An intutive way to think about this is that a zero order tensor is a scalar, a first order tensor is a vector, and a  second order tensor is a matrix ... for example the mixed tensor written above ( in 3 dimensions ) would appear as the following\n",
    "\n",
    "$$ \\bar{T}^i_r =\\left( \\begin{matrix} \\bar{T}^1_1 &\\bar{T}^1_2 & \\bar{T}^1_3 \\\\ \\bar{T}^2_1&\\bar{T}^2_2&\\bar{T}^2_3 \\\\ \\bar{T}^3_1&\\bar{T}^3_2&\\bar{T}^3_3  \\end{matrix}\\right) $$\n",
    "   \n",
    "and\n",
    "   \n",
    "$$\\frac{ \\partial \\bar{x}^{ i} }{ \\partial \\smash{x^{ j}}}= \\left(\\begin{matrix} \\frac{\\partial \\bar{x}^1}{\\partial x^1} &\\frac{\\partial \\bar{x}^1}{\\partial x^2} & \\frac{\\partial \\bar{x}^1}{\\partial x^3} \\\\\\ \\frac{\\partial \\bar{x}^2}{\\partial x^1} & \\frac{\\partial \\bar{x}^2}{\\partial x^2} & \\frac{\\partial \\bar{x}^2}{\\partial x^3} \\\\\\ \\frac{\\partial \\bar{x}^3}{\\partial x^1} & \\frac{\\partial \\bar{x}^3}{\\partial x^2} &\\frac{\\partial \\bar{x}^3}{\\partial x^3}  \\end{matrix}\\right)$$\n",
    "   \n",
    "and\n",
    "   \n",
    "$$\\frac{  \\partial x^{ s }  }{\\partial \\bar{x}^{ r } }=\\left( \\begin{matrix} \\frac{\\partial x^1}{\\partial \\bar{x}^1} &\\frac{\\partial x^1}{\\partial \\bar{x}^2} & \\frac{\\partial x^1}{\\partial \\bar{x}^3} \\\\\\ \\frac{\\partial x^2}{\\partial \\bar{x}^1} & \\frac{\\partial x^2}{\\partial \\bar{x}^2} & \\frac{\\partial x^2}{\\partial \\bar{x}^3} \\\\\\ \\frac{\\partial x^3}{\\partial \\bar{x}^1} & \\frac{\\partial x^3}{\\partial \\bar{x}^2} &\\frac{\\partial x^3}{\\partial \\bar{x}^3}  \\end{matrix}\\right) $$\n",
    "\n",
    "and $$\n",
    "T^j_s =\\left( \\begin{matrix} T^1_1 &T^1_2 & T^1_3 \\\\\\ T^2_1&T^2_2&T^2_3 \\\\\\ T^3_1&T^3_2&T^3_3  \\end{matrix}\\right) $$\n",
    "   \n",
    "and so clearly expanding up the full equation is a tedious and laborious process.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher Order Tensors\n",
    "   \n",
    "For a generalized vector field $\\mathbf T = T^{i_1,\\cdots i_p}_{r_1,\\cdots r_q}$ consisting of $(p+q)$ scalar fields, and is of rank $p+q$, contravariant off order p and covariant of order q defined in both coordinate systems, then if the components of the matrix field transform \n",
    "   \n",
    "   $$ \\large\\bar{T}^{i_1,\\cdots i_p}_{r_1,\\cdots r_q} =  T^{j_1,\\cdots j_p}_{s_1,\\cdots s_q} \\frac{ \\partial \\bar{x}^{ i_1} }{ \\partial \\smash{x^{ j_1}} }\\frac{ \\partial \\bar{x}^{ i_2} }{ \\partial \\smash{x^{ j_2}}} ... \\frac{ \\partial \\bar{x}^{ i_p} }{ \\partial \\smash{x^{ j_p}}} \\frac{ \\partial x^{ s_1} }{ \\partial \\bar{x}^{ r_1}} ... \\frac{ \\partial x^{ s_q} }{ \\partial \\bar{x}^{ r_q}} \\qquad\\qquad (1.6)$$\n",
    "   \n",
    "  This is a generalized mixed tensor of rank $p+q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Addition\n",
    "\n",
    "The sum of two tensors of the same rank and type also produce a tensor of the same rank and type . e.g  \n",
    "   \n",
    "   $$\\large T^{pq}_{r} = A^{pq}_{r} + B^{pq}_{r}\\qquad\\qquad (1.7)$$. \n",
    "   \n",
    "This operation is associative and commutative. The same is true for subtraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer Product\n",
    "   \n",
    "The outer product of two tensors is a tensor\n",
    "      \n",
    "$$\\large U^{i_1\\cdots i_ak_1\\cdots k_c}_{j_1\\cdots j_bl_d\\cdots l_d}= \\left(S^{i_1\\cdots i_a}_{j_1\\cdots j_b}\\cdot T^{k_1\\cdots k_c}_{l_d\\cdots l_d} \\right)\\qquad\\qquad (1.8)$$\n",
    "   \n",
    "of order $a + b + c + d$, and is covariant of order $b+d$ and contravariant of order $a+c$. The outer product is commutative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contraction\n",
    "   \n",
    "A contraction is defined by setting two indices equal for example setting some chosen index in the range $(i_1\\cdots i_a)$ equal to some index in the range $r_1\\cdots r_b)$, then the contraction of \n",
    "   \n",
    "$$\\large T^{i_1\\cdots i_a}_{r_1\\cdots r_b}$$ \n",
    "   \n",
    "is a tensor of rank $(a+b-2)$, covariant of order $b-1$ and contravariant of order $a-1$.\n",
    "\n",
    "This operation uses the fact that $\\frac{\\partial x^p}{\\partial x^q} = \\delta^p_q$ as in calculus, $\\frac{dx}{dx} = 1$, but the change in the x axis with respect to the z axis is zero, since they are orthogonal.\n",
    "\n",
    "> A contraction can result in a loss of information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The contraction of a second order tensor $T^i_j$ would be $T^i_i=T^1_1+T^2_2+T^3_3$ and is the trace of the tensor in matrix form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Product\n",
    "    \n",
    "This operation is equivalent to an outer product followed by a contraction.\n",
    "   \n",
    "If $T^i$ is a contravariant Tensor of rank 1 and $S_{ji}$ is covariant of rank 2 then since $T^i = \\bar{ T^j } \\frac{\\partial x^i}{\\partial \\bar{x}^j}$ and $S_{ji}= \\bar{S}_{pq}\\frac{\\partial \\bar{x}^p}{\\partial x^j}\\frac{\\partial \\bar{x}^q}{\\partial x^i} $ \n",
    "\n",
    "$$ (TS)_j = (T^i)(S_{ji}) = \\left(\\bar{ T^r } \\frac{\\partial x^i}{\\partial \\bar{x}^r}\\right) \\left(\\bar{S}_{pq}\\frac{\\partial \\bar{x}^p}{\\partial x^j}\\frac{\\partial \\bar{x}^q}{\\partial x^i} \\right) = \\color{red}{\\frac{\\partial x^i}{\\partial \\bar{x}^r}}\\color{blue}{ \\frac{\\partial \\bar{x}^q}{\\partial x^i} }\\color{black}{\\frac{\\partial \\bar{x}^p}{\\partial x^j} \\bar{T}^r \\bar{S}_{pq}} = \\delta_{\\color{red}{r}}^{\\color{blue}{q}}\\color{black}{\\frac{\\partial \\bar{x}^p}{\\partial x^j}} \\color{black}{\\bar{T}}^{\\color{red}{r}} \\color{black}{S}_{p\\color{blue}{q}} = \\color{black}{\\frac{\\partial \\bar{x}^p}{\\partial x^j} (\\bar{T S})_{p} } \\qquad\\qquad (1.9)$$\n",
    "   \n",
    "and the result is a covariant vector. The result of multipliying the product $\\frac{\\partial x^i}{\\partial \\bar{x}^r}\\frac{\\partial \\bar{x}^q}{\\partial x^i} = \\delta^q_r$ since the $x^i$'s cancel and the remaining differential quotient \n",
    "$\\frac{\\partial \\bar{x}^q}{\\partial \\bar{x}^r} = \\delta^q_r$ since this is equivalent to the change in x with respect to y when x is not a function of y when $r\\neq q$ and so those terms are zero, and when $r=q$ the terms are 1. The $\\delta_r^q$ term remaining then multiplies with the $\\bar{T}^r \\bar{S}_{pq}$ terms, effectively leaving the sum over p, since the other terms are zero. This second part is equivalent to a contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
